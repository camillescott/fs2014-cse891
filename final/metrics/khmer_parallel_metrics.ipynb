{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:fdb0733e346160e1c3e4078bf1c2656308301c55434a0a5e0e1b964ce32928c1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# khmer Parallel Performance Metrics\n",
      "#### Camille Scott\n",
      "#### Michigan State University\n",
      "#### GED Lab\n",
      "#### https://github.com/camillescott\n",
      "\n",
      "*khmer source code*: https://github.com/ged-lab/khmer\n",
      "\n",
      "*this notebook*: https://github.com/camillescott/fs2014-cse891/tree/master/final"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import khmer\n",
      "import screed\n",
      "import peasoup\n",
      "import seaborn as sns\n",
      "import pandas as pd\n",
      "from IPython.display import FileLink\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
      "warnings.filterwarnings(\"ignore\",category=UserWarning)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tall_size = (12,24)\n",
      "norm_size = (18,12)\n",
      "mpl_params = {'axes.titlesize': 24,\n",
      "               'axes.labelsize': 20,\n",
      "               'ytick.labelsize': 18,\n",
      "               'xtick.labelsize': 18\n",
      "               }\n",
      "sns.set(style='ticks', rc=mpl_params)\n",
      "%config InlineBackend.close_figures = False"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Generate Test Data\n",
      "\n",
      "Here, we'll generate some random test sequences of different sizes:\n",
      "\n",
      "1. Small (1,000 sequences of length 100)\n",
      "2. Medium (10,000 sequences of length 100)\n",
      "3. Large (100,000 sequences of length 100)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_files = [(1000, 'test-small.fa'), (10000, 'test-medium.fa'), (100000, 'test-large.fa')]\n",
      "for N, fn in test_files:\n",
      "    !make-random-transcriptome.py -N {N} -L 100 -o {fn}"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%ls -sh"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 12M\r\n",
        " 12K khmer_parallel_metrics.ipynb   48K single_threaded_time.pdf   56K \u001b[0m\u001b[01;35msingle_threaded_time.svg\u001b[0m  1.1M test-medium.fa               108K test-small.fa\r\n",
        " 40K single_threaded_time.eps       36K \u001b[01;35msingle_threaded_time.png\u001b[0m   11M test-large.fa             4.0K test_readparser_threaded.py\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Test Read Parsing\n",
      "\n",
      "First, let's test `screed` and `khmer.ReadParser` in a naive, single-threaded manner."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_screed_single_threaded(fn):\n",
      "    for r in screed.open(fn):\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_readparser_single_threaded(fn):\n",
      "    for r in khmer.ReadParser(fn):\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "screed_results = {}\n",
      "for _, fn in test_files:\n",
      "    results = %timeit -n 1 -r 10 -o test_screed_single_threaded(fn)\n",
      "    screed_results[fn] = results.all_runs"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 10: 6.24 ms per loop\n",
        "1 loops, best of 10: 62.1 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 10: 625 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "readparser_results = {}\n",
      "for _, fn in test_files:\n",
      "    results = %timeit -n 1 -r 10 -o test_readparser_single_threaded(fn)\n",
      "    readparser_results[fn] = results.all_runs"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 10: 1.41 ms per loop\n",
        "1 loops, best of 10: 12.6 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1 loops, best of 10: 127 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with peasoup.plot.FigManager('single_threaded_time', figsize=norm_size, show=False, ncols=2,\n",
      "                             tight_layout=False, sharey=True) as (fig, ax):\n",
      "\n",
      "    _ = pd.DataFrame(screed_results).boxplot(ax=ax[0], fontsize=16)\n",
      "    ax[0].set_title('$screed$ Time, Single-Threaded')\n",
      "    ax[0].set_ylabel('Exec Time (s)')\n",
      "    _ = pd.DataFrame(readparser_results).boxplot(ax=ax[1], fontsize=16)\n",
      "    ax[1].set_title('$khmer.ReadParser$ Time, Single-Threaded')\n",
      "FileLink('single_threaded_time.svg', )"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "html": [
        "<a href='single_threaded_time.svg' target='_blank'>single_threaded_time.svg</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "/w/fs2014-cse891/final/metrics/single_threaded_time.svg"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "<center>\n",
      "![single-threaded results](single_threaded_time.svg \"\")\n",
      "</center>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The first thing we can see is that `khmer.ReadParser` performs significantly better than `screed`, even without taking threading into account. `screed` is not thread-safe; so, how does `khmer.ReadParser` scale with threading?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Multi-threaded `khmer.ReadParser`\n",
      "\n",
      "`khmer.ReadParser` is *supposed* to be compatible with python threads. So, let's confirm that's the case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_readparser_threaded(fn, n_threads=4):\n",
      "\n",
      "    import operator\n",
      "    import threading\n",
      "\n",
      "    reads_count_1thr = 0\n",
      "    rparser = khmer.ReadParser(fn)\n",
      "    for read in rparser:\n",
      "        reads_count_1thr += 1\n",
      "\n",
      "    def count_reads(rparser, counters, tnum):\n",
      "        counters[tnum] = reduce(operator.add, (1 for read in rparser))\n",
      "\n",
      "    config = khmer.get_config()\n",
      "    bufsz = config.get_reads_input_buffer_size()\n",
      "    config.set_reads_input_buffer_size(n_threads * 64 * 1024)\n",
      "    threads = []\n",
      "    reads_counts_per_thread = [0] * n_threads\n",
      "    rparser = khmer.ReadParser(fn, n_threads)\n",
      "    for tnum in xrange(n_threads):\n",
      "        t = \\\n",
      "            threading.Thread(\n",
      "                target=count_reads,\n",
      "                args=[rparser, reads_counts_per_thread, tnum]\n",
      "            )\n",
      "        threads.append(t)\n",
      "        t.start()\n",
      "    for t in threads:\n",
      "        t.join()\n",
      "    config.set_reads_input_buffer_size(bufsz)\n",
      "\n",
      "    print reads_count_1thr, reads_counts_per_thread, sum(reads_counts_per_thread)\n",
      "    #assert reads_count_1thr == sum(reads_counts_per_thread)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "readparser_results = {}\n",
      "for np in range(1,5):\n",
      "    try:\n",
      "        results = %timeit -n 1 -r 20 -o test_readparser_threaded('test-large.fa', np)\n",
      "    except Exception as e:\n",
      "        print e\n",
      "    readparser_results[np] = results.all_runs"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100000 [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [100000] 100000\n",
        "1 loops, best of 20: 278 ms per loop\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [50095, 49902] 99997\n",
        "1 loops, best of 20: 226 ms per loop\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [33403, 33398, 33196] 99997\n",
        "1 loops, best of 20: 276 ms per loop\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 24854, 25043] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [25052, 25048, 25043, 24854] 99997\n",
        "1 loops, best of 20: 259 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with peasoup.plot.FigManager('readparser_threaded_time', figsize=norm_size, show=False,\n",
      "                             tight_layout=False) as (fig, ax):\n",
      "\n",
      "    ax.set_ylabel('Exec Time (s)')\n",
      "    ax.set_xlabel('Num Threads')\n",
      "    ax.set_ylim(bottom=0)\n",
      "    _ = pd.DataFrame(readparser_results).boxplot(ax=ax, fontsize=16)\n",
      "    ax.set_title('$khmer.ReadParser$: Total time parsing test-large.fa')\n",
      "FileLink('readparser_threaded_time.svg', )"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "html": [
        "<a href='readparser_threaded_time.svg' target='_blank'>readparser_threaded_time.svg</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "/w/fs2014-cse891/final/metrics/readparser_threaded_time.svg"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "<center>\n",
      "![multi-threaded results](readparser_threaded_time.svg \"\")\n",
      "</center>\n",
      "<h4 align=\"center\">ReadParser scales to two theads, but then drops off</h4>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### `khmer.ReadParser`: Larger Files\n",
      "\n",
      "We can see that the threading works, and there is a minor scaling benefit. Does a benefit start to show more clearly for larger filesizes?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!make-random-transcriptome.py -N 1000000 -L 100 -o test-extra-large.fa"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "readparser_xl_results = {}\n",
      "for np in range(1,5):\n",
      "    try:\n",
      "        results = %timeit -n 1 -r 20 -o test_readparser_threaded('test-extra-large.fa', np)\n",
      "    except Exception as e:\n",
      "        print e\n",
      "    readparser_xl_results[np] = results.all_runs"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000000 [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1000000] 1000000\n",
        "1 loops, best of 20: 2.71 s per loop\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [500000, 499983] 999983\n",
        "1 loops, best of 20: 2.24 s per loop\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [333346, 333324, 333313] 999983\n",
        "1 loops, best of 20: 2.76 s per loop\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249987, 249994, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [250013, 249994, 249987, 249989] 999983\n",
        "1 loops, best of 20: 2.65 s per loop\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with peasoup.plot.FigManager('readparser_xl_threaded_time', figsize=norm_size,\n",
      "                             tight_layout=False, show=False) as (fig, ax):\n",
      "\n",
      "    ax.set_ylabel('Exec Time (s)')\n",
      "    ax.set_xlabel('Num Threads')\n",
      "    _ = pd.DataFrame(readparser_xl_results).boxplot(ax=ax, fontsize=16)\n",
      "    ax.set_title('$khmer.ReadParser$: Total time parsing test-extra-large.fa')\n",
      "    ax.set_ylim(bottom=0)\n",
      "FileLink('readparser_xl_threaded_time.svg')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "html": [
        "<a href='readparser_xl_threaded_time.svg' target='_blank'>readparser_xl_threaded_time.svg</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "/w/fs2014-cse891/final/metrics/readparser_xl_threaded_time.svg"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "<center>\n",
      "![multi-threaded results](readparser_xl_threaded_time.svg \"\")\n",
      "</center>\n",
      "<h4 align=\"center\">Results with 1m reads are similar</h4>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Abundance Filtering Performance\n",
      "\n",
      "`scripts/filter-abund.py` is currently implemented using `thread_utils.ThreaderSequenceProcessor`. Last I new, this did not scale; let's confirm. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!load-into-counting.py -k 20 -x 1e9 test-large.ht test-large.fa"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'load-into-counting.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "\r\n",
        "PARAMETERS:\r\n",
        " - kmer size =    20 \t\t(-k)\r\n",
        " - n tables =     4 \t\t(-N)\r\n",
        " - min tablesize = 1e+09 \t(-x)\r\n",
        "\r\n",
        "Estimated memory usage is 4e+09 bytes (n_tables x min_tablesize)\r\n",
        "--------\r\n",
        "Saving k-mer counting table to test-large.ht\r\n",
        "Loading kmers from sequences in ['test-large.fa']\r\n",
        "making k-mer counting table\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "consuming input test-large.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saving test-large.ht\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fp rate estimated to be 0.000\r\n",
        "DONE.\r\n",
        "wrote to: test-large.ht.info\r\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tsp_results = {}\n",
      "for np in range(1,5):\n",
      "    try:\n",
      "        results = %timeit -n 1 -r 10 -o !filter-abund.py -V -C 2 -Z 5 -T {np} -o test-large.filt.fa test-large.ht test-large.fa\n",
      "    except Exception as e:\n",
      "        print e\n",
      "    tsp_results[np] = results.all_runs"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 10: 5.17 s per loop\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n",
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 10: 6.1 s per loop\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 10: 7.16 s per loop\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'filter-abund.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * Q Zhang et al., arXiv:1309.2975 [q-bio.GN]\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "loading hashtable\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K: 20\r\n",
        "filtering test-large.fa\r\n",
        "starting threads\r\n",
        "starting writer\r\n",
        "loading...\r\n",
        "... filtering 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done loading in sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DONE writing.\r\n",
        "processed 100000 / wrote 100000 / removed 0\r\n",
        "processed 10000000 bp / wrote 10000000 bp / removed 0 bp\r\n",
        "discarded 0.0%\r\n",
        "output in test-large.filt.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 10: 7.03 s per loop\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with peasoup.plot.FigManager('tsp_threaded_time', figsize=norm_size,\n",
      "                             tight_layout=False, show=False) as (fig, ax):\n",
      "\n",
      "    ax.set_ylabel('Exec Time (s)')\n",
      "    ax.set_xlabel('Num Threads')\n",
      "    _ = pd.DataFrame(tsp_results).boxplot(ax=ax, fontsize=16)\n",
      "    ax.set_title('$scripts/filter-abund.py$: Total time processing test-large.fa')\n",
      "    ax.set_ylim(bottom=0)\n",
      "FileLink('tsp_threaded_time.svg')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "html": [
        "<a href='tsp_threaded_time.svg' target='_blank'>tsp_threaded_time.svg</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "/w/fs2014-cse891/final/metrics/tsp_threaded_time.svg"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "<center>\n",
      "![multi-threaded results](tsp_threaded_time.svg \"\")\n",
      "</center>\n",
      "<h4 align=\"center\">Threading hurts performance</h4>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Partitioning Performance\n",
      "\n",
      "We've seen that threading hurts performance for `scripts/filter-abund.py`; is the effect on partitioning similar? We'll test with some real data this time, a subset of the assembled lamprey transcriptome."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "part_results = {}\n",
      "for np in range(1,5):\n",
      "    try:\n",
      "        results = %timeit -n 1 -r 5 -o !do-partition.py -k 20 -x 1e9 --no-big-traverse -T {np} test-partitioning-part test-partitioning.fa\n",
      "    except Exception as e:\n",
      "        print e\n",
      "    part_results[np] = results.all_runs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'do-partition.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * J Pell et al., PNAS, 2014 (PMID 22847406)\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "\r\n",
        "PARAMETERS:\r\n",
        " - kmer size =    20 \t\t(-k)\r\n",
        " - n tables =     4 \t\t(-N)\r\n",
        " - min tablesize = 1e+09 \t(-x)\r\n",
        "\r\n",
        "Estimated memory usage is 5e+08 bytes (n_tables x min_tablesize / 8)\r\n",
        "--------\r\n",
        "Saving k-mer presence table to test-partitioning-part\r\n",
        "Loading kmers from sequences in ['test-partitioning.fa']\r\n",
        "--\r\n",
        "SUBSET SIZE 100000\r\n",
        "N THREADS 1\r\n",
        "--\r\n",
        "making k-mer presence table\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "consuming input test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fp rate estimated to be 0.000\r\n",
        "** This script brakes for lumps: stop_big_traversals is true.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "enqueued 21 subset tasks\r\n",
        "starting 21 threads\r\n",
        "---\r\n",
        "starting: test-partitioning-part 0\r\n",
        "starting: test-partitioning-part 1\r\n",
        "starting: test-partitioning-part 2\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 3\r\n",
        "starting: test-partitioning-part 4\r\n",
        "starting: test-partitioning-part 5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 6\r\n",
        "starting: test-partitioning-part 7\r\n",
        "starting: test-partitioning-part 8\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 9\r\n",
        "starting: test-partitioning-part 10\r\n",
        "starting: test-partitioning-part 11\r\n",
        "starting: test-partitioning-part 12\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 13\r\n",
        "starting: test-partitioning-part 14\r\n",
        "starting: test-partitioning-part 15\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 16\r\n",
        "starting: test-partitioning-part 17\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 18\r\n",
        "starting: test-partitioning-part 19\r\n",
        "done starting threads\r\n",
        "starting: test-partitioning-part 20\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 183101536872-220314205471: 100000 <- 66804\r\n",
        "saving: test-partitioning-part 7\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        "...subset-part 732739314530-848345555074: 100000 <- 66871\r\n",
        "saving: test-partitioning-part 19\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 126518117596-150077702791: 100000 <- 65807\r\n",
        "saving: test-partitioning-part 5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 509208122894-549145528830: 100000 <- 66696\r\n",
        "saving: test-partitioning-part 15\r\n",
        "...subset-part 418872719272-461512905087: 100000 <- 67854\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        "...subset-part 0-16927530712: 100000 <- 68371\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exitingsaving:saving:  test-partitioning-parttest-partitioning-part 0 13\r\n",
        "\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        "...subset-part 296360116604-346831687575: 100000 <- 67694\r\n",
        "saving: test-partitioning-part 10\r\n",
        "...subset-part 150077702791-183101536872: 100000 <- 67410\r\n",
        "saving: test-partitioning-part 6\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 549145528830-595535043242: 100000 <- 67199\r\n",
        "saving: test-partitioning-part 16\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 664075331230-732739314530: 100000 <- 67703\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saving: test-partitioning-part exiting18\r\n",
        "...subset-part 595535043242-664075331230: 100000 <- 68524\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 220314205471-257195523100: 100000 <- 68602\r\n",
        "\r\n",
        "exiting\r\n",
        " saving: test-partitioning-part 17saving: test-partitioning-part\r\n",
        " exiting\r\n",
        "20\r\n",
        "saving: test-partitioning-part 8\r\n",
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 461512905087-509208122894: 100000 <- 68441\r\n",
        "...subset-part 16927530712-38192043186: 100000 <- 69247\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 346831687575-379759339330: 100000 <- 68872\r\n",
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 68892891496-96608460593: 100000 <- 68557\r\n",
        " exitingsaving: test-partitioning-part saving:...subset-part 96608460593-126518117596: 100000 <- 67984\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 379759339330-418872719272: 100000 <- 70301\r\n",
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " saving: test-partitioning-part 3exiting saving: test-partitioning-part 4\r\n",
        " saving: test-partitioning-part 1211\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "test-partitioning-part 14\r\n",
        "\r\n",
        "saving: test-partitioning-part 1\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 38192043186-68892891496: 100000 <- 69948\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        "...subset-part 257195523100-296360116604: 100000 <- 69653\r\n",
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exitingexiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        " \r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        " saving: test-partitioning-part 9saving:\r\n",
        " test-partitioning-part 2\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        "---\r\n",
        "done making subsets! see test-partitioning-part.subset.*.pmap\r\n",
        "loading 21 pmap files (first one: test-partitioning-part.subset.18.pmap)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.18.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.3.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.11.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.5.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.13.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.6.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.20.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.12.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.1.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.15.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.8.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.16.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.7.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.19.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.9.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.4.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.2.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.14.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.17.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.0.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.10.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing pmap files\r\n",
        "outputting partitions for test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... output_partitions 100000 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... output_partitions 200000 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "output 122147 partitions for test-partitioning.fa\r\n",
        "partitions are in test-partitioning.fa.part\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'do-partition.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * J Pell et al., PNAS, 2014 (PMID 22847406)\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "\r\n",
        "PARAMETERS:\r\n",
        " - kmer size =    20 \t\t(-k)\r\n",
        " - n tables =     4 \t\t(-N)\r\n",
        " - min tablesize = 1e+09 \t(-x)\r\n",
        "\r\n",
        "Estimated memory usage is 5e+08 bytes (n_tables x min_tablesize / 8)\r\n",
        "--------\r\n",
        "Saving k-mer presence table to test-partitioning-part\r\n",
        "Loading kmers from sequences in ['test-partitioning.fa']\r\n",
        "--\r\n",
        "SUBSET SIZE 100000\r\n",
        "N THREADS 1\r\n",
        "--\r\n",
        "making k-mer presence table\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "consuming input test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fp rate estimated to be 0.000\r\n",
        "** This script brakes for lumps: stop_big_traversals is true.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "enqueued 21 subset tasks\r\n",
        "starting 21 threads\r\n",
        "---\r\n",
        "starting: test-partitioning-part 1\r\n",
        " starting: test-partitioning-part 0\r\n",
        " starting: test-partitioning-part 2\r\n",
        "starting: test-partitioning-part 3\r\n",
        " starting: test-partitioning-part 4\r\n",
        "starting: test-partitioning-part 5\r\n",
        " starting: test-partitioning-part 6\r\n",
        "starting: test-partitioning-part 7\r\n",
        "starting: test-partitioning-part 9\r\n",
        "starting: test-partitioning-part 8\r\n",
        "starting: test-partitioning-part 10\r\n",
        "starting: test-partitioning-part 11\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 12\r\n",
        "starting: test-partitioning-part 13\r\n",
        "starting: test-partitioning-part 14\r\n",
        "starting: test-partitioning-part 15\r\n",
        "starting: test-partitioning-part 16\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 17\r\n",
        "starting: test-partitioning-part 18\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 19\r\n",
        "starting: test-partitioning-part 20\r\n",
        " done starting threads\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 126518117596-150077702791: 100000 <- 65807\r\n",
        "saving: test-partitioning-part 5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 664075331230-732739314530: 100000 <- 67703\r\n",
        "saving: test-partitioning-part 18\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saving: test-partitioning-part 20\r\n",
        "...subset-part 732739314530-848345555074: 100000 <- 66871\r\n",
        "saving: test-partitioning-part 19\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        "...subset-part 549145528830-595535043242: 100000 <- 67199\r\n",
        "saving: test-partitioning-part 16\r\n",
        "...subset-part 418872719272-461512905087: 100000 <- 67854\r\n",
        "saving: test-partitioning-part 13\r\n",
        "...subset-part 68892891496-96608460593: 100000 <- 68557\r\n",
        "saving: test-partitioning-part 3\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 509208122894-549145528830: 100000 <- 66696\r\n",
        "saving: test-partitioning-part 15\r\n",
        "...subset-part 296360116604-346831687575: 100000 <- 67694\r\n",
        "saving: test-partitioning-part 10\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 346831687575-379759339330: 100000 <- 68872\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        " saving: test-partitioning-part 11\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 96608460593-126518117596: 100000 <- 67984\r\n",
        "...subset-part 0-16927530712: 100000 <- 68371\r\n",
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 183101536872-220314205471: 100000 <- 66804\r\n",
        "...subset-part 150077702791-183101536872: 100000 <- 67410\r\n",
        "...subset-part 595535043242-664075331230: 100000 <- 68524\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " saving: test-partitioning-part ...subset-part 220314205471-257195523100: 100000 <- 68602\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        " exiting\r\n",
        "...subset-part 38192043186-68892891496: 100000 <- 69948\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 461512905087-509208122894: 100000 <- 68441\r\n",
        " exiting\r\n",
        " saving: test-partitioning-part 17saving: saving: saving: saving:test-partitioning-part  test-partitioning-part70\r\n",
        "test-partitioning-part saving:\r\n",
        " saving:...subset-part 257195523100-296360116604: 100000 <- 69653\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting4\r\n",
        "8\r\n",
        " \r\n",
        "test-partitioning-part 14\r\n",
        "\r\n",
        " test-partitioning-part 6saving: test-partitioning-part 9\r\n",
        "\r\n",
        " test-partitioning-part 2\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 16927530712-38192043186: 100000 <- 69247\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 379759339330-418872719272: 100000 <- 70301\r\n",
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saving: exiting\r\n",
        "saving: test-partitioning-parttest-partitioning-part  1\r\n",
        "12\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        " exiting\r\n",
        "---\r\n",
        "done making subsets! see test-partitioning-part.subset.*.pmap\r\n",
        "loading 21 pmap files (first one: test-partitioning-part.subset.18.pmap)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.18.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.3.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.11.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.5.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.13.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.6.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.20.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.12.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.1.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.15.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.8.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.16.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.7.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.19.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.9.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.4.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.2.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.14.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.17.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.0.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.10.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing pmap files\r\n",
        "outputting partitions for test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... output_partitions 100000 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... output_partitions 200000 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "output 122147 partitions for test-partitioning.fa\r\n",
        "partitions are in test-partitioning.fa.part\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'do-partition.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * J Pell et al., PNAS, 2014 (PMID 22847406)\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "\r\n",
        "PARAMETERS:\r\n",
        " - kmer size =    20 \t\t(-k)\r\n",
        " - n tables =     4 \t\t(-N)\r\n",
        " - min tablesize = 1e+09 \t(-x)\r\n",
        "\r\n",
        "Estimated memory usage is 5e+08 bytes (n_tables x min_tablesize / 8)\r\n",
        "--------\r\n",
        "Saving k-mer presence table to test-partitioning-part\r\n",
        "Loading kmers from sequences in ['test-partitioning.fa']\r\n",
        "--\r\n",
        "SUBSET SIZE 100000\r\n",
        "N THREADS 1\r\n",
        "--\r\n",
        "making k-mer presence table\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "consuming input test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fp rate estimated to be 0.000\r\n",
        "** This script brakes for lumps: stop_big_traversals is true.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "enqueued 21 subset tasks\r\n",
        "starting 21 threads\r\n",
        "---\r\n",
        "starting: test-partitioning-partstarting: test-partitioning-part 0 1\r\n",
        "\r\n",
        " starting: test-partitioning-part 2\r\n",
        "starting: test-partitioning-part 3\r\n",
        "starting: test-partitioning-part 4\r\n",
        "starting: test-partitioning-part 5\r\n",
        "starting: test-partitioning-part 6\r\n",
        "starting: test-partitioning-part 7\r\n",
        "starting: test-partitioning-part 8\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 9\r\n",
        "starting: test-partitioning-part 10\r\n",
        "starting: test-partitioning-part 11\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 12\r\n",
        "starting: test-partitioning-part 13\r\n",
        "starting: test-partitioning-part 14\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 15\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 16\r\n",
        "starting: test-partitioning-part 17\r\n",
        "starting: test-partitioning-part 18\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 19\r\n",
        "done starting threads\r\n",
        "starting: test-partitioning-part 20\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 183101536872-220314205471: 100000 <- 66804\r\n",
        "saving: test-partitioning-part 7\r\n",
        "...subset-part 126518117596-150077702791: 100000 <- 65807\r\n",
        "saving: test-partitioning-part 5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 509208122894-549145528830: 100000 <- 66696\r\n",
        "saving: test-partitioning-part 15\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 732739314530-848345555074: 100000 <- 66871\r\n",
        "saving: test-partitioning-part 19\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 664075331230-732739314530: 100000 <- 67703\r\n",
        "saving: test-partitioning-part 18\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 96608460593-126518117596: 100000 <- 67984\r\n",
        "...subset-part 595535043242-664075331230: 100000 <- 68524\r\n",
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 418872719272-461512905087: 100000 <- 67854\r\n",
        "...subset-part 296360116604-346831687575: 100000 <- 67694\r\n",
        " exitingsaving:saving:  test-partitioning-part 17\r\n",
        " saving: test-partitioning-part 4\r\n",
        "test-partitioning-part 13\r\n",
        "saving: test-partitioning-part 10\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 549145528830-595535043242: 100000 <- 67199\r\n",
        "saving: test-partitioning-part 16\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 150077702791-183101536872: 100000 <- 67410\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 461512905087-509208122894: 100000 <- 68441\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 0-16927530712: 100000 <- 68371\r\n",
        "...subset-part 16927530712-38192043186: 100000 <- 69247\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 346831687575-379759339330: 100000 <- 68872\r\n",
        "saving: exiting\r\n",
        " saving: test-partitioning-part 0...subset-part 68892891496-96608460593: 100000 <- 68557\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saving: exiting\r\n",
        "\r\n",
        "saving: test-partitioning-partsaving:test-partitioning-part  test-partitioning-part14saving:  1 \r\n",
        "test-partitioning-part3 exiting\r\n",
        "\r\n",
        "\r\n",
        "test-partitioning-part 6\r\n",
        "saving: test-partitioning-part 20\r\n",
        "exiting\r\n",
        " 11\r\n",
        "...subset-part 257195523100-296360116604: 100000 <- 69653\r\n",
        "saving: test-partitioning-part 9\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 220314205471-257195523100: 100000 <- 68602\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 379759339330-418872719272: 100000 <- 70301\r\n",
        " exiting\r\n",
        "...subset-part 38192043186-68892891496: 100000 <- 69948\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        "saving: test-partitioning-part 8\r\n",
        "saving: test-partitioning-part 2saving:\r\n",
        " test-partitioning-part 12\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        "---\r\n",
        "done making subsets! see test-partitioning-part.subset.*.pmap\r\n",
        "loading 21 pmap files (first one: test-partitioning-part.subset.18.pmap)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.18.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.3.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.11.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.5.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.13.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.6.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.20.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.12.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.1.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.15.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.8.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.16.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.7.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.19.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.9.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.4.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.2.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.14.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.17.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.0.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.10.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing pmap files\r\n",
        "outputting partitions for test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... output_partitions 100000 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... output_partitions 200000 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "output 122147 partitions for test-partitioning.fa\r\n",
        "partitions are in test-partitioning.fa.part\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'do-partition.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * J Pell et al., PNAS, 2014 (PMID 22847406)\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "\r\n",
        "PARAMETERS:\r\n",
        " - kmer size =    20 \t\t(-k)\r\n",
        " - n tables =     4 \t\t(-N)\r\n",
        " - min tablesize = 1e+09 \t(-x)\r\n",
        "\r\n",
        "Estimated memory usage is 5e+08 bytes (n_tables x min_tablesize / 8)\r\n",
        "--------\r\n",
        "Saving k-mer presence table to test-partitioning-part\r\n",
        "Loading kmers from sequences in ['test-partitioning.fa']\r\n",
        "--\r\n",
        "SUBSET SIZE 100000\r\n",
        "N THREADS 1\r\n",
        "--\r\n",
        "making k-mer presence table\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "consuming input test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fp rate estimated to be 0.000\r\n",
        "** This script brakes for lumps: stop_big_traversals is true.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "enqueued 21 subset tasks\r\n",
        "starting 21 threads\r\n",
        "---\r\n",
        "starting: test-partitioning-part 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 1\r\n",
        "starting: test-partitioning-part 2\r\n",
        "starting: test-partitioning-part 3\r\n",
        "starting: test-partitioning-part starting: test-partitioning-part 5\r\n",
        "4\r\n",
        "starting: test-partitioning-part 6\r\n",
        "starting: test-partitioning-part 7\r\n",
        "starting: test-partitioning-part 8\r\n",
        "starting: test-partitioning-part 9\r\n",
        "starting: test-partitioning-part 10\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 11\r\n",
        "starting: test-partitioning-part 12\r\n",
        "starting: test-partitioning-part 13\r\n",
        "starting: test-partitioning-part 14\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 15\r\n",
        "starting: test-partitioning-part 16\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 17\r\n",
        "starting: test-partitioning-part 18\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 19\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done starting threads\r\n",
        "starting: test-partitioning-part 20\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 126518117596-150077702791: 100000 <- 65807\r\n",
        "saving: test-partitioning-part 5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 732739314530-848345555074: 100000 <- 66871\r\n",
        "saving: test-partitioning-part 19\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 150077702791-183101536872: 100000 <- 67410\r\n",
        "saving: test-partitioning-part 6\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 418872719272-461512905087: 100000 <- 67854\r\n",
        "saving: test-partitioning-part 13\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 509208122894-549145528830: 100000 <- 66696\r\n",
        "saving: test-partitioning-part 15\r\n",
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 549145528830-595535043242: 100000 <- 67199\r\n",
        "...subset-part 96608460593-126518117596: 100000 <- 67984\r\n",
        "saving: test-partitioning-part 16saving:exiting\r\n",
        "\r\n",
        " test-partitioning-part 4\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 183101536872-220314205471: 100000 <- 66804\r\n",
        "exiting\r\n",
        " saving: test-partitioning-part 7...subset-part 0-16927530712: 100000 <- 68371\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 664075331230-732739314530: 100000 <- 67703\r\n",
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        "saving: test-partitioning-part \r\n",
        " saving: test-partitioning-part 20\r\n",
        "0\r\n",
        "saving: test-partitioning-part 18\r\n",
        "...subset-part 595535043242-664075331230: 100000 <- 68524\r\n",
        "saving: test-partitioning-part 17\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 68892891496-96608460593: 100000 <- 68557\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        "...subset-part 461512905087-509208122894: 100000 <- 68441\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 220314205471-257195523100: 100000 <- 68602\r\n",
        "...subset-part 346831687575-379759339330: 100000 <- 68872\r\n",
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ...subset-part 296360116604-346831687575: 100000 <- 67694\r\n",
        "...subset-part 16927530712-38192043186: 100000 <- 69247\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        "saving:...subset-part 38192043186-68892891496: 100000 <- 69948\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        "saving:saving:  test-partitioning-partsaving: test-partitioning-part 10\r\n",
        "saving:  test-partitioning-parttest-partitioning-part  11saving: test-partitioning-part3 1\r\n",
        " \r\n",
        "\r\n",
        " 14\r\n",
        " saving:test-partitioning-part 2\r\n",
        " test-partitioning-part 8\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 379759339330-418872719272: 100000 <- 70301\r\n",
        "...subset-part 257195523100-296360116604: 100000 <- 69653\r\n",
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exitingexiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exitingexiting\r\n",
        "saving:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        " test-partitioning-part 9\r\n",
        "saving: test-partitioning-part 12\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        "---\r\n",
        "done making subsets! see test-partitioning-part.subset.*.pmap\r\n",
        "loading 21 pmap files (first one: test-partitioning-part.subset.18.pmap)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.18.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.3.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.11.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.5.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.13.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.6.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.20.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.12.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.1.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.15.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.8.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.16.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.7.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.19.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.9.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.4.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.2.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.14.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.17.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.0.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.10.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing pmap files\r\n",
        "outputting partitions for test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... output_partitions 100000 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... output_partitions 200000 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "output 122147 partitions for test-partitioning.fa\r\n",
        "partitions are in test-partitioning.fa.part\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'do-partition.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * J Pell et al., PNAS, 2014 (PMID 22847406)\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "\r\n",
        "PARAMETERS:\r\n",
        " - kmer size =    20 \t\t(-k)\r\n",
        " - n tables =     4 \t\t(-N)\r\n",
        " - min tablesize = 1e+09 \t(-x)\r\n",
        "\r\n",
        "Estimated memory usage is 5e+08 bytes (n_tables x min_tablesize / 8)\r\n",
        "--------\r\n",
        "Saving k-mer presence table to test-partitioning-part\r\n",
        "Loading kmers from sequences in ['test-partitioning.fa']\r\n",
        "--\r\n",
        "SUBSET SIZE 100000\r\n",
        "N THREADS 1\r\n",
        "--\r\n",
        "making k-mer presence table\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "consuming input test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fp rate estimated to be 0.000\r\n",
        "** This script brakes for lumps: stop_big_traversals is true.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "enqueued 21 subset tasks\r\n",
        "starting 21 threads\r\n",
        "---\r\n",
        "starting: test-partitioning-part 0\r\n",
        " starting: test-partitioning-part 1\r\n",
        "starting: test-partitioning-part 2\r\n",
        "starting: test-partitioning-part 3\r\n",
        "starting: test-partitioning-part 4\r\n",
        "starting: test-partitioning-part 6\r\n",
        " starting: test-partitioning-part 5\r\n",
        "starting: test-partitioning-part 8\r\n",
        " starting: test-partitioning-part 7\r\n",
        "starting: test-partitioning-part 9\r\n",
        "starting: test-partitioning-part 10\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 11\r\n",
        "starting: test-partitioning-part 12\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 13\r\n",
        "starting: test-partitioning-part 14\r\n",
        "starting: test-partitioning-part 15\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 16\r\n",
        "starting: test-partitioning-part 17\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 18\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 19\r\n",
        "done starting threads\r\n",
        "starting: test-partitioning-part 20\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 732739314530-848345555074: 100000 <- 66871\r\n",
        "saving: test-partitioning-part 19\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 126518117596-150077702791: 100000 <- 65807\r\n",
        "saving: test-partitioning-part 5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 509208122894-549145528830: 100000 <- 66696\r\n",
        "saving: test-partitioning-part 15\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 183101536872-220314205471: 100000 <- 66804\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exitingsaving: test-partitioning-part 7\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 418872719272-461512905087: 100000 <- 67854\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 664075331230-732739314530: 100000 <- 67703\r\n",
        "...subset-part 220314205471-257195523100: 100000 <- 68602\r\n",
        "exiting saving: test-partitioning-part 13\r\n",
        "saving: test-partitioning-part 18\r\n",
        "\r\n",
        "saving: test-partitioning-part 8\r\n",
        "...subset-part 96608460593-126518117596: 100000 <- 67984\r\n",
        "saving: test-partitioning-part 4\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        " saving: test-partitioning-part 20\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 296360116604-346831687575: 100000 <- 67694\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting...subset-part 68892891496-96608460593: 100000 <- 68557\r\n",
        "...subset-part 549145528830-595535043242: 100000 <- 67199\r\n",
        "...subset-part 16927530712-38192043186: 100000 <- 69247\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        " saving: test-partitioning-part 3\r\n",
        "\r\n",
        "...subset-part 150077702791-183101536872: 100000 <- 67410\r\n",
        "...subset-part 38192043186-68892891496: 100000 <- 69948\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 461512905087-509208122894: 100000 <- 68441\r\n",
        "...subset-part 346831687575-379759339330: 100000 <- 68872\r\n",
        " exitingsaving:saving: saving: test-partitioning-part 16 test-partitioning-partsaving: saving:\r\n",
        "\r\n",
        "test-partitioning-part 1\r\n",
        "test-partitioning-part 6\r\n",
        " test-partitioning-part 2 10\r\n",
        "\r\n",
        "saving: test-partitioning-part 11\r\n",
        "saving: test-partitioning-part 14\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 0-16927530712: 100000 <- 68371\r\n",
        "...subset-part 595535043242-664075331230: 100000 <- 68524\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n",
        "...subset-part 379759339330-418872719272: 100000 <- 70301\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exitingexiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...subset-part 257195523100-296360116604: 100000 <- 69653\r\n",
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        "saving: test-partitioning-part 9\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saving:exiting\r\n",
        "saving: test-partitioning-part saving:12\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "test-partitioning-part exiting\r\n",
        " 17test-partitioning-part 0\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exiting\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exiting\r\n",
        "---\r\n",
        "done making subsets! see test-partitioning-part.subset.*.pmap\r\n",
        "loading 21 pmap files (first one: test-partitioning-part.subset.18.pmap)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.18.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.3.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.11.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.5.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.13.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.6.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.20.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.12.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.1.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.15.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.8.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.16.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.7.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.19.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.9.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.4.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.2.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.14.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.17.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.0.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "merging test-partitioning-part.subset.10.pmap\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing pmap files\r\n",
        "outputting partitions for test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... output_partitions 100000 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... output_partitions 200000 0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "output 122147 partitions for test-partitioning.fa\r\n",
        "partitions are in test-partitioning.fa.part\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 5: 1min 55s per loop\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'do-partition.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * J Pell et al., PNAS, 2014 (PMID 22847406)\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "\r\n",
        "PARAMETERS:\r\n",
        " - kmer size =    20 \t\t(-k)\r\n",
        " - n tables =     4 \t\t(-N)\r\n",
        " - min tablesize = 1e+09 \t(-x)\r\n",
        "\r\n",
        "Estimated memory usage is 5e+08 bytes (n_tables x min_tablesize / 8)\r\n",
        "--------\r\n",
        "Saving k-mer presence table to test-partitioning-part\r\n",
        "Loading kmers from sequences in ['test-partitioning.fa']\r\n",
        "--\r\n",
        "SUBSET SIZE 100000\r\n",
        "N THREADS 2\r\n",
        "--\r\n",
        "making k-mer presence table\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "consuming input test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fp rate estimated to be 0.000\r\n",
        "** This script brakes for lumps: stop_big_traversals is true.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "enqueued 21 subset tasks\r\n",
        "starting 21 threads\r\n",
        "---\r\n",
        "starting: test-partitioning-part 0starting: test-partitioning-part 1\r\n",
        "\r\n",
        "starting: test-partitioning-part 2\r\n",
        "starting: test-partitioning-part 3\r\n",
        "starting: test-partitioning-part 4\r\n",
        "starting: test-partitioning-part 5\r\n",
        "starting: test-partitioning-part 6\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 7\r\n",
        "starting: test-partitioning-part 8\r\n",
        "starting: test-partitioning-part 9\r\n",
        "starting: test-partitioning-part 10\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 11\r\n",
        "starting: starting:test-partitioning-part  13test-partitioning-part\r\n",
        " 12\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 14\r\n",
        "starting: test-partitioning-part 15\r\n",
        "starting: test-partitioning-part 16\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 17\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 18\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting: test-partitioning-part 19\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done starting threads\r\n",
        "starting: test-partitioning-part 20\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "^C\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'do-partition.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * J Pell et al., PNAS, 2014 (PMID 22847406)\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "\r\n",
        "PARAMETERS:\r\n",
        " - kmer size =    20 \t\t(-k)\r\n",
        " - n tables =     4 \t\t(-N)\r\n",
        " - min tablesize = 1e+09 \t(-x)\r\n",
        "\r\n",
        "Estimated memory usage is 5e+08 bytes (n_tables x min_tablesize / 8)\r\n",
        "--------\r\n",
        "Saving k-mer presence table to test-partitioning-part\r\n",
        "Loading kmers from sequences in ['test-partitioning.fa']\r\n",
        "--\r\n",
        "SUBSET SIZE 100000\r\n",
        "N THREADS 2\r\n",
        "--\r\n",
        "making k-mer presence table\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "consuming input test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "^C\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'do-partition.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * J Pell et al., PNAS, 2014 (PMID 22847406)\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "\r\n",
        "PARAMETERS:\r\n",
        " - kmer size =    20 \t\t(-k)\r\n",
        " - n tables =     4 \t\t(-N)\r\n",
        " - min tablesize = 1e+09 \t(-x)\r\n",
        "\r\n",
        "Estimated memory usage is 5e+08 bytes (n_tables x min_tablesize / 8)\r\n",
        "--------\r\n",
        "Saving k-mer presence table to test-partitioning-part\r\n",
        "Loading kmers from sequences in ['test-partitioning.fa']\r\n",
        "--\r\n",
        "SUBSET SIZE 100000\r\n",
        "N THREADS 2\r\n",
        "--\r\n",
        "making k-mer presence table\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "consuming input test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "^C\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "^C\r\n",
        "local variable 'child' referenced before assignment\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'do-partition.py' in khmer.\r\n",
        "|| You are running khmer version 1.2-rc2-6-gc5dee21\r\n",
        "|| You are also using screed version 0.7\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. doi: 10.6084/m9.figshare.979190\r\n",
        "||   * J Pell et al., PNAS, 2014 (PMID 22847406)\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n",
        "\r\n",
        "PARAMETERS:\r\n",
        " - kmer size =    20 \t\t(-k)\r\n",
        " - n tables =     4 \t\t(-N)\r\n",
        " - min tablesize = 1e+09 \t(-x)\r\n",
        "\r\n",
        "Estimated memory usage is 5e+08 bytes (n_tables x min_tablesize / 8)\r\n",
        "--------\r\n",
        "Saving k-mer presence table to test-partitioning-part\r\n",
        "Loading kmers from sequences in ['test-partitioning.fa']\r\n",
        "--\r\n",
        "SUBSET SIZE 100000\r\n",
        "N THREADS 2\r\n",
        "--\r\n",
        "making k-mer presence table\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "consuming input test-partitioning.fa\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "^C\r\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-48-89c080cbb65b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'timeit -n 1 -r 5 -o !do-partition.py -k 20 -x 1e9 --no-big-traverse -T {np} test-partitioning-part test-partitioning.fa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/camille/anaconda/envs/bio/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2203\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2204\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2205\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2207\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/camille/anaconda/envs/bio/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2124\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2125\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2126\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2127\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/camille/anaconda/envs/bio/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n",
        "\u001b[1;32m/home/camille/anaconda/envs/bio/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/camille/anaconda/envs/bio/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m   1014\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m         \u001b[0mall_runs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m         \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mquiet\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/camille/anaconda/envs/bio/lib/python2.7/timeit.pyc\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/camille/anaconda/envs/bio/lib/python2.7/timeit.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
        "\u001b[1;32m/home/camille/anaconda/envs/bio/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36msystem_piped\u001b[1;34m(self, cmd)\u001b[0m\n\u001b[0;32m   2254\u001b[0m         \u001b[1;31m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2255\u001b[0m         \u001b[1;31m# Instead, we store the exit_code in user_ns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2256\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_exit_code'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msystem_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/camille/anaconda/envs/bio/lib/python2.7/site-packages/IPython/utils/_process_posix.pyc\u001b[0m in \u001b[0;36msystem\u001b[1;34m(self, cmd)\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;31m# Ensure the subprocess really is terminated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                 \u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[1;31m# add isalive check, to ensure exitstatus is set:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/camille/anaconda/envs/bio/lib/python2.7/site-packages/IPython/external/pexpect/_pexpect.pyc\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self, force)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIGHUP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1096\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelayafterterminate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "part_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "{1: [136.59699511528015,\n",
        "  115.4859390258789,\n",
        "  115.33226799964905,\n",
        "  117.78190612792969,\n",
        "  116.23118495941162]}"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Outstanding Issues\n",
      "\n",
      "### Threadsafe Counting Increment\n",
      "\n",
      "Currently, incrementing counts is not threadsafe. If we look at `CountingHash::count`, the current code is:\n",
      "\n",
      "```\n",
      "unsigned int  n_full\t  = 0;\n",
      "\n",
      "for (unsigned int i = 0; i < _n_tables; i++) {\n",
      "    const HashIntoType bin = khash % _tablesizes[i];\n",
      "    // NOTE: Technically, multiple threads can cause the bin to spill\n",
      "    //\t over max_count a little, if they all read it as less than\n",
      "    //\t max_count before any of them increment it.\n",
      "    //\t However, do we actually care if there is a little\n",
      "    //\t bit of slop here? It can always be trimmed off later, if\n",
      "    //\t that would help with stats.\n",
      "    if ( _max_count > _counts[ i ][ bin ] ) {\n",
      "        __sync_add_and_fetch( *(_counts + i) + bin, 1 );\n",
      "    } else {\n",
      "        n_full++;\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "See [doxygen](http://ci.ged.msu.edu/job/khmer-master/doxygen/counting_8hh_source.html#l00158) for full code.\n",
      "\n",
      "The comment notes the possible problem: a counter could be incremented between the read and the increment. However, the \"slop\" is considerable, because `unsigned char` behaves like a modulo 255 ring, meaning that if we overrun, we wrap back around to zero, throwing off the count considerably. An obvious and fast solution is to simply wrap the `if` statement in a lock.\n",
      "\n",
      "**TODO**: *test performance hit of lock*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}